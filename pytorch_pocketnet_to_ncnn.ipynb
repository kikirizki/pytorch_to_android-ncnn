{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/os-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fsbAUieBD8v",
        "outputId": "1d64ef57-eeee-4b3b-d694-fb5039e674a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.5 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.5 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raVsTi9UFe4r",
        "outputId": "61e8f6c4-a239-4dd9-fd0a-3ec22780cdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:40tcmalloc: large alloc 1147494400 bytes == 0x254c000 @  0x7fa2c983b615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwbKQvA3lClc",
        "outputId": "4c1a5d48-be42-4948-cce4-9e8f78a697f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'PocketNet'...\n",
            "remote: Enumerating objects: 622, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 622 (delta 32), reused 30 (delta 27), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (622/622), 73.18 MiB | 36.55 MiB/s, done.\n",
            "Resolving deltas: 100% (346/346), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sDnU-DuotD0nkJ_1AitlqZGu1Torwifu\n",
            "To: /content/295672backbone.pth\n",
            "100% 4.24M/4.24M [00:00<00:00, 76.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/kikirizki/PocketNet\n",
        "!gdown 1sDnU-DuotD0nkJ_1AitlqZGu1Torwifu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bicgzrczv9Y7",
        "outputId": "2c1b9854-a207-4720-d4a6-f8e2e20fff29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PocketNet\n",
            "call Factorized\n",
            "call Factorized\n"
          ]
        }
      ],
      "source": [
        "%cd /content/PocketNet\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from backbones.augment_cnn import AugmentCNN \n",
        "import backbones.genotypes as gt\n",
        "\n",
        "from configs.config_PocketNetS128 import config as cfg\n",
        "\n",
        "\n",
        "\n",
        "genotype = gt.from_str(cfg.genotypes[\"softmax_casia\"])\n",
        "backbone=AugmentCNN(C=cfg.channel, n_layers=cfg.n_layers, genotype=genotype, stem_multiplier=4,\n",
        "                       emb=cfg.embedding_size)\n",
        "backbone.load_state_dict(torch.load(\"/content/295672backbone.pth\"))\n",
        "backbone.eval()\n",
        "x = torch.randn([1,3,112,112])\n",
        "torch.onnx.export(backbone,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"pocketnet.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,\n",
        "                  input_names = ['data'],   # the model's input names\n",
        "                  output_names = ['fc1']\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxQE9oSjKMH-",
        "outputId": "f5fde2ce-020f-4651-d35e-97282a5fcea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!wget -q https://github.com/Tencent/ncnn/releases/download/20220701/ncnn-20220701-ubuntu-1804.zip\n",
        "!unzip -q ncnn-20220701-ubuntu-1804.zip\n",
        "\n",
        "import os\n",
        "os.environ['PATH'] += \":/content/ncnn-20220701-ubuntu-1804/bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq_eqQk5KfAj",
        "outputId": "46e90c55-36d8-4691-ee0c-d49a0a62e5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PocketNet\n"
          ]
        }
      ],
      "source": [
        "%cd /content/PocketNet\n",
        "!onnx2ncnn \\\n",
        "  pocketnet.onnx \\\n",
        "  pocketnet.param \\\n",
        "  pocketnet.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P-5P2KcL-Tt",
        "outputId": "608f6f20-5c46-4546-fdf5-086cf7b2f985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "vulkan-utils is already the newest version (1.1.126.0+dfsg1-1~gpu18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "Input layer data without shape info, shape_inference skipped\n",
            "Input layer data without shape info, estimate_memory_footprint skipped\n"
          ]
        }
      ],
      "source": [
        "!apt install vulkan-utils\n",
        "# https://github.com/Tencent/ncnn/wiki/use-ncnnoptimize-to-optimize-model\n",
        "!ncnnoptimize \\\n",
        "  pocketnet.param \\\n",
        "  pocketnet.bin \\\n",
        "  pocketnet-opt.param \\\n",
        "  pocketnet-opt.bin \\\n",
        "  65536"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuhDeRQCCK3v",
        "outputId": "ccc3b0d1-16b6-4943-a570-7c43e8b9426e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu102'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "e5FO_ZlXLmRu",
        "outputId": "468af21c-bdb3-4922-e1ea-83f061293ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘pocketnet’: File exists\n",
            "  adding: pocketnet/ (stored 0%)\n",
            "  adding: pocketnet/pocketnet.param (deflated 86%)\n",
            "  adding: pocketnet/pocketnet.bin (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3495be49-c19f-43d8-8d9b-4a72beade3a3\", \"pocketnet.zip\", 1752450)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!mkdir pocketnet\n",
        "!cp pocketnet-opt.param pocketnet/pocketnet.param\n",
        "!cp pocketnet-opt.bin pocketnet/pocketnet.bin\n",
        "\n",
        "!zip -r pocketnet.zip pocketnet\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"pocketnet.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pytorch_pocketnet_to_ncnn.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}